# Xueqiu Alt-Data Pipeline

An end-to-end Python project for **crawling**, **summarizing**, and **analyzing** investor sentiment from the [Xueqiu.com](https://xueqiu.com) financial community.

The system automatically:
1. **Crawls** posts from multiple Xueqiu tabs (`fund`, `etf`, `hot`, `7x24`, etc.) via Playwright.
2. **Summarizes** them using the Fireworks API (`gpt-oss-20b` or other LLM).
3. **Generates Markdown reports** grouped by tab with sentiment, top tickers, and daily timelines.

---

## âš™ï¸ 1. Installation

### Requirements
- Python â‰¥ 3.10
- Playwright (Chromium)
- OpenAI / Fireworks API Key

### Clone Repository
```bash
git clone https://github.com/Hwi3/Xueqiu-Crawler-and-Report-Generator.git
```

### Create Virtual Environment
```bash
conda create -n linqalpha_code_test python=3.11
conda activate linqalpha_code_test
pip install -r requirements.txt
```

### Install Playwright browsers
```bash
playwright install chromium
```

---

## ğŸ” 2. Environment Setup

Create a `.env` file in the project root (or edit `.env.example`):

```bash
FIREWORKS_API_KEY=sk-your-fireworks-key
```

> ğŸ”¸ The summarizer automatically loads this key via `dotenv`.  
> If `.env` is missing, it will raise `RuntimeError: Missing FIREWORKS_API_KEY env variable`.

---

##  3. Configuration (YAML)

Edit the file `config.yaml` to control job settings:

```yaml
job: job_20251109
tabs: all          # or comma-separated keys, e.g. "fund,etf,7x24"
mode: all          # one of [crawl, summarize, report, all]
scroll: 3          # number of scroll rounds for crawling
sum_limit: 50      # number of posts to summarize per tab (None = all)
```

---

##  4. Running the Pipeline

Run the main program â€” it reads configuration automatically from YAML:

After writing a configuration
run below

```bash
python main.py
```


### Modes
| Mode | Description |
|------|--------------|
| `crawl` | Crawls data only (`storage/run_<date>/raw/*.json`) |
| `summarize` | Summarizes existing raw data via Fireworks API |
| `report` | Generates Markdown report from summary files |
| `all` | Performs all 3 sequentially |

---

##  5. Crawling Details

Crawling uses **Playwright + BeautifulSoup**.

- Each tab (e.g., `fund`, `etf`, `hot`, `7x24`) is loaded and scrolled.
- Post data includes:  
  `id`, `url`, `tab`, `author`, `title`, `text`, `symbols`, `post_time`.

Example crawl output:
```json
{
  "id": "360598503",
  "tab": "7x24",
  "author": "Airbus",
  "text": "å¾·å›½æ‹Ÿæ–¥èµ„10äº¿æ¬§å…ƒé‡‡è´­ç©ºå®¢ä½œæˆ˜ç›´å‡æœºâ€¦",
  "post_time": "2025-11-09T02:16:40.000Z",
  "url": "https://xueqiu.com/5124430882/360598503"
}
```

---

##  6. Summarization (Fireworks API)

Each post is summarized using the **Fireworks Chat Completions API**:

```python
url = "https://api.fireworks.ai/inference/v1/chat/completions"
payload = {
  "model": "accounts/fireworks/models/gpt-oss-20b",
  "temperature": 0.6,
  "messages": [{"role": "user", "content": "<post text>"}]
}
```

Summaries are stored in:
```
storage/run_<date>/summary/posts_<tab>.json
```

Each record contains:
```json
{
  "id": "360598503",
  "tab": "7x24",
  "themes": ["defense", "military"],
  "sentiment": "positive",
  "entities": ["Airbus"]
}
```

---

##  7. Reporting

The final Markdown report is generated by `reporting/report_generator.py`.

**Features:**
- Groups all posts by **tab**
- Summarizes **themes**, **tickers**, and **sentiment**
- For `7x24` tab: shows **chronological timeline** sorted by post_time
- Saved to:
  ```
  storage/<job>/reports/final_report.md
  ```
---

## ğŸ“ 8. Folder Structure

```
LinqAlpha_codetest/
â”‚
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ browser_crawler.py         # Playwright-based crawler
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ summarizer.py              # Fireworks API summarizer
â”‚
â”œâ”€â”€ reporting/
â”‚   â”œâ”€â”€ report_generator.py        # Markdown analytics report
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ run_YYYYMMDD_HHMM/         # Auto-generated job folders
â”‚       â”œâ”€â”€ raw/                   # Crawled posts
â”‚       â”œâ”€â”€ summary/               # Summarized posts
â”‚       â””â”€â”€ reports/               # Markdown reports
â”‚
â”œâ”€â”€ config.yaml
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ‘¨â€ğŸ’» Author
**Park Seunghwi**  
Singapore Â· Data Science & Quantitative Finance  
ğŸ“§ [park.s@u.nus.edu](mailto:park.s@u.nus.edu)
